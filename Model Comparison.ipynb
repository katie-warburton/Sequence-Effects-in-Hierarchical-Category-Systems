{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007dbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from Python_Scripts import OrderedCategorySystem as OCS\n",
    "from Python_Scripts import generate_plots as plots\n",
    "from Python_Scripts import order_analyses as analyses\n",
    "from Python_Scripts import RationalCategorySystem as RCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde579c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "F =  [12, 13, 15, 14, 16, 18, 17, 19, 20]\n",
    "B =  [20, 19, 17, 18, 16, 14, 15, 13, 12]\n",
    "M1 =  [16, 17, 15, 18, 14, 19, 13, 20, 12]\n",
    "M2 = [16, 15, 17, 14, 18, 13, 19, 12, 20]\n",
    "\n",
    "NEW = [i for i in range(9, 24)]\n",
    "ALL = NEW + [1, 3, 29, 31]\n",
    "\n",
    "SHIFT = 3\n",
    "DISTRACTORS = [1, 3, 29, 31]\n",
    "\n",
    "ITEMS = ['I09', 'I10', 'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19', 'I20', 'I21', 'I22', 'I23']\n",
    "\n",
    "LEFT = ITEMS[:9]\n",
    "CENTRE = ITEMS[3:12]\n",
    "RIGHT = ITEMS[6:]\n",
    "\n",
    "LOCS = [('L', LEFT),\n",
    "        ('C', CENTRE), \n",
    "        ('R', RIGHT)]\n",
    "ORDERS = [('f', 0, [1, 2, 3, 4, 5, 6, 7, 8]),\n",
    "          ('m', 4, [0, 1, 2, 3, 5, 6, 7, 8]),\n",
    "          ('b', 8, [0, 1, 2, 3, 4, 5, 6, 7])]\n",
    "\n",
    "item_space = [i for i in range(1, 32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcffd3",
   "metadata": {},
   "source": [
    "### Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a53d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allParticipants = pd.read_csv('Results/participant_data.csv')\n",
    "allParticipants =  allParticipants[(allParticipants['ATTEMPTS'] < 3) & (allParticipants['TOTAL_ERRORS'] < 4) & (allParticipants['POOL'] == 'prolific2')]\n",
    "participants = allParticipants['P_ID'].tolist()\n",
    "\n",
    "participant_df = pd.read_csv('Results/trial_data.csv')    \n",
    "participant_df = participant_df[participant_df['P_ID'].isin(participants)]\n",
    "\n",
    "cat_assigns = ITEMS + ['I01', 'I03', 'I29', 'I31']\n",
    "others = participant_df.columns.difference(cat_assigns)\n",
    "sequence_df = pd.read_csv('Results/sequence_data.csv')\n",
    "\n",
    "trial_df = (\n",
    "  participant_df[others]\n",
    "    .assign(ITEMS = participant_df[cat_assigns].agg(\n",
    "            lambda row: {k: v for k, v in row.items() if not pd.isna(v)},\n",
    "            axis=1\n",
    "    )\n",
    "  )\n",
    ")\n",
    "seq_df = (\n",
    "  sequence_df[['P_ID', 'DEPTH', 'LOC', 'ORDER', 'STIMULI']]\n",
    "  .assign(SEQUENCE = sequence_df[[f't{i+1:02}' for i in range(13)]].agg(\n",
    "            lambda row: {k: v for k, v in row.items()},\n",
    "            axis=1\n",
    "    )   \n",
    "  )\n",
    ")\n",
    "\n",
    "data_df = trial_df.merge(seq_df, on=['P_ID', 'DEPTH', 'LOC', 'ORDER', 'STIMULI'], how='inner')\n",
    "participant_trials = list(data_df.to_dict('index').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_rcm_data(trial_data):\n",
    "    rcmData = {t['P_ID']:[] for t in trial_data}\n",
    "    for t in trial_data:\n",
    "        item_assignments = {int(key[1:]): val for key, val in t['ITEMS'].items()}\n",
    "        sequence = {key: int(val) for key, val in t['SEQUENCE'].items()}\n",
    "        rcmData[t['P_ID']].append({'CHOICES': item_assignments, 'SEQUENCE': sequence, 'DEPTH': t['DEPTH'], 'LOC': t['LOC'], 'ORDER': t['ORDER'], 'STIMULI': t['STIMULI']})\n",
    "    return rcmData\n",
    "\n",
    "def get_trial_loglike(model, choices, order, item_space, alpha=0.0, uniform=None):\n",
    "    log_like = 0\n",
    "    for t in range(len(order)):\n",
    "        it = order[f't{t+1:02}']\n",
    "        choice = choices[it]\n",
    "        item_rep = item_space[it-1]\n",
    "        if 0.0 < alpha < 1.0 and uniform is not None:\n",
    "            prob_dist, choice_idx = model.get_item_likelihood(item_rep, choice)\n",
    "            mixture = np.logaddexp(np.log(1 - alpha) + prob_dist[choice_idx], np.log(alpha) + np.log(uniform))\n",
    "        elif alpha == 1.0 and uniform is not None:\n",
    "            mixture = np.log(uniform)\n",
    "        else:\n",
    "            prob_dist, choice_idx = model.get_item_likelihood(item_rep, choice)\n",
    "            mixture =  prob_dist[choice_idx]\n",
    "        log_like += mixture\n",
    "    return log_like\n",
    "\n",
    "def get_participant_loglike_rcm(data, item_space, c=0.5, alpha=0.0, diff3=False):\n",
    "    total_ll = 0.0\n",
    "    existing_items = [item_space[i] for i in [1, 2, 3, 5, 6, 7, 23, 24, 25, 27, 28, 29]]\n",
    "    mu_0 = [np.mean(item_space)]\n",
    "    var_0 = [np.var(item_space)]\n",
    "    for trial in data:\n",
    "        d = trial['DEPTH']\n",
    "        order = trial['SEQUENCE']\n",
    "        choices = trial['CHOICES']\n",
    "        if diff3 and d == 3:\n",
    "            syst = ['L1', 'L1', 'L1', 'L2', 'L2', 'L2', 'R2', 'R2', 'R2', 'R1', 'R1', 'R1']\n",
    "            max_new = 3\n",
    "            uniform = 1/7\n",
    "        else:\n",
    "            syst = ['L',  'L',  'L',  'L',  'L',  'L',  'R',  'R',  'R',  'R',  'R',  'R']\n",
    "            max_new = 1\n",
    "            uniform = 1/3\n",
    "            if d == 3:\n",
    "                choices = {key: val[0] for key, val in choices.items()}\n",
    "        rcm = RCS.RationalModel(c, mu_0, var_0,  np.array([1.0]),  np.array([1.0]), partition=syst, stimuli=existing_items, max_new_clusters=max_new)\n",
    "        total_ll += get_trial_loglike(rcm, choices, order, item_space, alpha, uniform)\n",
    "    return total_ll\n",
    "\n",
    "def get_total_log_like_rcm(trial_data, item_space, c=0.5, alpha=0.0, diff3=False):\n",
    "    total_ll = 0.0\n",
    "    for _, p_data in trial_data.items():\n",
    "        total_ll += get_participant_loglike_rcm(p_data, item_space, c, alpha, diff3)\n",
    "    return total_ll\n",
    "\n",
    "def cross_val_branch(data, temps, alphas, outer_k=5, inner_k=5):\n",
    "    participant_keys = list(data.keys())\n",
    "    outer_kf = KFold(n_splits=outer_k, shuffle=True, random_state=42)\n",
    "    \n",
    "    outer_val_lls = []\n",
    "    best_hyperparams_per_fold = []\n",
    "\n",
    "    for outer_train_idx, outer_test_idx in outer_kf.split(participant_keys):\n",
    "        outer_train_keys = [participant_keys[i] for i in outer_train_idx]\n",
    "        outer_test_keys = [participant_keys[i] for i in outer_test_idx]\n",
    "\n",
    "        outer_train_data = {k: data[k] for k in outer_train_keys}\n",
    "        outer_test_data = {k: data[k] for k in outer_test_keys}\n",
    "\n",
    "        # --- INNER CV: select best (t, alpha) ---\n",
    "        inner_kf = KFold(n_splits=inner_k, shuffle=True, random_state=42)\n",
    "        mean_val_ll_per_hyper = {}\n",
    "        for t in temps:\n",
    "            for alpha in alphas:\n",
    "                val_lls_inner = []\n",
    "                skip_alpha = False\n",
    "\n",
    "                for inner_train_idx, inner_val_idx in inner_kf.split(outer_train_keys):\n",
    "                    inner_train_keys = [outer_train_keys[i] for i in inner_train_idx]\n",
    "                    inner_val_keys = [outer_train_keys[i] for i in inner_val_idx]\n",
    "\n",
    "                    inner_train_data = {k: data[k] for k in inner_train_keys}\n",
    "                    inner_val_data = {k: data[k] for k in inner_val_keys}\n",
    "\n",
    "                    # Reset prev_ll per inner fold\n",
    "                    prev_ll_train = None  \n",
    "\n",
    "                    ll_train = OCS.get_total_log_like(inner_train_data, t, alpha)\n",
    "\n",
    "                    if prev_ll_train is not None and ll_train < prev_ll_train:\n",
    "                        skip_alpha = True\n",
    "                        break\n",
    "\n",
    "                    prev_ll_train = ll_train\n",
    "\n",
    "                    # Compute validation LL\n",
    "                    ll_val = OCS.get_total_log_like(inner_val_data, t, alpha)\n",
    "                    n_trials = sum(len(data[k]) for k in inner_val_data)\n",
    "                    val_lls_inner.append(ll_val / n_trials)\n",
    "\n",
    "                if skip_alpha:\n",
    "                    break  # stop alpha loop for this t\n",
    "\n",
    "                # Only add to dictionary if we have computed validation LLs\n",
    "                if val_lls_inner:\n",
    "                    mean_val_ll_per_hyper[(t, alpha)] = np.mean(val_lls_inner)\n",
    "                # Select hyperparameters that maximize inner validation LL\n",
    "                best_t, best_alpha = max(mean_val_ll_per_hyper, key=mean_val_ll_per_hyper.get)\n",
    "                best_hyperparams_per_fold.append((best_t, best_alpha))\n",
    "\n",
    "                # --- OUTER FOLD: evaluate predictive performance ---\n",
    "                ll_test = OCS.get_total_log_like(outer_test_data, best_t, best_alpha)\n",
    "                n_trials_test = sum(len(data[k]) for k in outer_test_data)\n",
    "                outer_val_lls.append(ll_test / n_trials_test)\n",
    "\n",
    "    mean_val_ll = np.mean(outer_val_lls)\n",
    "\n",
    "    print(f\"mean per-trial validation LL: {mean_val_ll:.4f}\")\n",
    "\n",
    "    return outer_val_lls, best_hyperparams_per_fold, mean_val_ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData, D, lookupTree = OCS.precompute_possible_scores(participant_trials, item_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52eed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg errors = 0.08\n"
     ]
    }
   ],
   "source": [
    "error_rate2 = np.mean([e['ERRORS']/4 for e in participant_trials if e['DEPTH'] == 2])\n",
    "error_rate3 = np.mean([e['ERRORS']/4 for e in participant_trials if e['DEPTH'] == 3])\n",
    "\n",
    "num2 = len([t for t in participant_trials if t['DEPTH'] == 2])\n",
    "num3 = len(participant_trials) - num2\n",
    "# for 2 level \n",
    "er2 = (3/2)*error_rate2\n",
    "# for 3 level\n",
    "er3 = (7/4)*error_rate3\n",
    "\n",
    "print(f'Avg errors = {round(((er2*num2) + (er3)*num3)/len(participant_trials), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae47cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = np.linspace(1.0, 5, 41)\n",
    "alphas = np.linspace(0, 0.5, 51)\n",
    "\n",
    "soft_t, soft_a, soft_ll = OCS.find_best_params(allData, (temps, alphas), False)\n",
    "\n",
    "# can't have alpha = 0 in deterministic model\n",
    "det_a, det_ll = OCS.find_best_params(allData, (alphas[1:]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfb0b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKMM\n",
      "\tSoftmax: -6103.1855845144255, T = 1.0, alpha = 0.15\n",
      "\tDeterministic: -6719.433185177522, alpha = 0.27\n"
     ]
    }
   ],
   "source": [
    "print('CKMM')\n",
    "print(f'\\tSoftmax: {soft_ll}, T = {soft_t}, alpha = {soft_a}')\n",
    "print(f'\\tDeterministic: {det_ll}, alpha = {det_a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca38f1",
   "metadata": {},
   "source": [
    "### Rational Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3b5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7302.143956858989\n"
     ]
    }
   ],
   "source": [
    "item_values = (np.array(item_space) - min(item_space)) / (max(item_space) - min(item_space))\n",
    "item_values = [np.array([val]) for val in item_values.tolist()]\n",
    "\n",
    "data_rcm = format_rcm_data(participant_trials)\n",
    "ll_rcm = get_total_log_like_rcm(data_rcm, item_values, 0.3, alpha=0.0, diff3=True)\n",
    "print(ll_rcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe4885",
   "metadata": {},
   "source": [
    "### Random assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b6f1151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13061.001257833486\n"
     ]
    }
   ],
   "source": [
    "num_3 = len([t for t in participant_trials if t['DEPTH'] == 3])\n",
    "num_2 = len([t for t in participant_trials if t['DEPTH'] == 2])\n",
    " \n",
    "random_2level = np.log(1/3)*13 # categorizing 4 distractors + 9 novel stimuli\n",
    "random_3level = np.log(1/7)*13\n",
    "random_likelihood = (random_2level*num_2) + (random_3level*num_3)\n",
    "print(random_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
